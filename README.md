# Decision-Tree-on-Cars-datasets

## üöÄ Project Overview
This project applies a Decision Tree model to a car evaluation dataset to determine the condition of a vehicle based on various attributes. Decision Trees are a powerful machine learning algorithm for classification tasks, and this project demonstrates how they can be used to make data-driven decisions about cars.

## üìÇ Dataset
The dataset includes various features of cars, such as:
- **Buying Price:** The cost of the car.
- **Maintenance Cost:** Estimated cost of upkeep.
- **Number of Doors:** Total number of doors on the vehicle.
- **Persons Capacity:** Number of people the car can seat.
- **Luggage Boot Size:** Storage capacity of the car.
- **Safety Rating:** Safety level (low, medium, high).

## üõ†Ô∏è Tools & Libraries Used
- **Python** for coding and data manipulation
- **Pandas & NumPy** for data handling
- **Matplotlib & Seaborn** for visualization
- **Scikit-learn** for building and evaluating the Decision Tree model

## üìä Project Workflow
1. **Data Preprocessing:** Load and clean the dataset.
2. **Exploratory Data Analysis (EDA):** Visualize data distributions and relationships.
3. **Model Building:** Train a Decision Tree classifier.
4. **Evaluation:** Assess model accuracy using metrics like accuracy score, confusion matrix, and classification report.
5. **Visualization:** Plot the Decision Tree for interpretability.

## ‚ö° How to Run the Project
1. Clone the repository:
```bash
git clone https://github.com/yourusername/Decision-Tree-on-Cars-datasets.git
```
2. Navigate to the project directory:
```bash
cd Decision-Tree-on-Cars-datasets
```
3. Install the required packages:
```bash
pip install -r requirements.txt
```
4. Run the Jupyter notebook or Python script:
```bash
jupyter notebook car_decision_tree.ipynb
```

## üìà Results
The Decision Tree model successfully classifies car conditions with a high level of accuracy. The visualized tree provides insights into which features are most important for decision-making.

## ü§î Future Improvements
- Try other algorithms (Random Forest, XGBoost) for better accuracy.
- Perform hyperparameter tuning to optimize the tree.
- Add more features or enrich the dataset.

